{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_esp/blob/main/Perceptron/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yyyz9kf3US8",
        "outputId": "a27e0194-f47f-46c1-f54a-9d1a6f54f2cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_esp.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'redes_neurais_esp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV4FHtiCf-HP"
      },
      "source": [
        "# **Código da Rede Neural Perceptron**\n",
        "\n",
        "Abaixo é apresentado um código do perceptron. Prestem atenção nas equações e etapas de treinamento.\n",
        "\n",
        "\n",
        "##Somatório:\n",
        "\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "##Atualização dos Pesos:\n",
        "\n",
        "Δ𝑤_𝑖=𝜂(𝑡−𝑜)𝑥_𝑖\n",
        "\n",
        "𝑤_(𝑖+1)=𝑤_𝑖+Δ𝑤_𝑖\n",
        "\n",
        "## Parâmetros: \n",
        "𝑛 = Número de exemplos\n",
        "\n",
        "𝑥_𝑖= Vetor de características do exemplo 𝑖\n",
        "\n",
        "𝑤_𝑖= Peso da conexão 𝑖\n",
        "\n",
        "𝑇 = Limiar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EHLTqwin5It"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron(object):\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=0.2, nIterations=100, learning_rate=0.01):\n",
        "        self.nIterations = nIterations\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.zeros(no_of_inputs)\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "        #.dot = produto de dois arrays (somatório entre entrada e peso)\n",
        "        summation = np.dot(inputs, self.weights)\n",
        "        #print(summation)\n",
        "        if summation >= self.threshold:\n",
        "          activation = 1\n",
        "        else:\n",
        "          activation = 0            \n",
        "        return activation\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "        for _ in range(self.nIterations):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                #delta = w_i + n*(t-o)*x\n",
        "                delta = self.learning_rate * (label - prediction) * inputs\n",
        "                #w_(i+1) = w_i + delta \n",
        "                self.weights += delta\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCCgVXChwpm"
      },
      "source": [
        "#Exemplo dado em Sala de Aula:\n",
        "\n",
        "##Operador AND\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9zGKKaqf6I5",
        "outputId": "2d856540-99ff-4536-9f7f-7e0a45b59c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_inputs = []\n",
        "training_inputs.append(np.array([1, 1]))\n",
        "training_inputs.append(np.array([1, 0]))\n",
        "training_inputs.append(np.array([0, 1]))\n",
        "training_inputs.append(np.array([0, 0]))\n",
        "\n",
        "labels = np.array([1, 0, 0, 0])\n",
        "\n",
        "perceptron = Perceptron(2)\n",
        "perceptron.train(training_inputs, labels)\n",
        "\n",
        "inputs = np.array([1, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 1\n",
        "\n",
        "inputs = np.array([0, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 0\n",
        "\n",
        "weights_and_1 = perceptron.weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsGJ-wqziDp2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Exercícios:\n",
        "\n",
        "1. Altere o código abaixo e rode para apenas uma execução. Qual o resultado para [1,1] e [0,1]?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Tj6MWWkL73",
        "outputId": "02e84b25-c76e-4b4c-c94e-70fea6ba85b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_inputs = []\n",
        "training_inputs.append(np.array([1, 1]))\n",
        "training_inputs.append(np.array([1, 0]))\n",
        "training_inputs.append(np.array([0, 1]))\n",
        "training_inputs.append(np.array([0, 0]))\n",
        "\n",
        "labels = np.array([1, 0, 0, 0])\n",
        "\n",
        "perceptron = Perceptron(2, nIterations=1)\n",
        "perceptron.train(training_inputs, labels)\n",
        "\n",
        "inputs = np.array([1, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 1\n",
        "\n",
        "inputs = np.array([0, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 0\n",
        "\n",
        "weights_and_2 = perceptron.weights"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhoPmRkRkVH2"
      },
      "source": [
        "2. Altere o código abaixo para o operador XOR. Deixe os parâmetros no padrão. Qual o resultado para [1,1] e [0,1]? \n",
        "\n",
        "3. Porque o resultado deu errado na questão anterior?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCPZN-NmH5z",
        "outputId": "a8cee21c-a694-4668-c7d0-2d26cddc6fe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_inputs = []\n",
        "training_inputs.append(np.array([1, 1]))\n",
        "training_inputs.append(np.array([1, 0]))\n",
        "training_inputs.append(np.array([0, 1]))\n",
        "training_inputs.append(np.array([0, 0]))\n",
        "\n",
        "labels = np.array([0, 1, 1, 0])\n",
        "\n",
        "perceptron = Perceptron(2)\n",
        "perceptron.train(training_inputs, labels)\n",
        "\n",
        "inputs = np.array([1, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 1\n",
        "\n",
        "inputs = np.array([0, 1])\n",
        "p = perceptron.predict(inputs) \n",
        "print(p)\n",
        "#=> 0\n",
        "\n",
        "weights_xor = perceptron.weights\n",
        "\n",
        "print(\"\\n3. Porque o resultado deu errado na questão anterior?\")\n",
        "print(\"O número de iterações não foi o suficiente para o Perceptron encontrar os pesos ótimos.\")\n",
        "print(\"Pesos do primeiro AND Perceptron:\",weights_and_1)\n",
        "print(\"Pesos do segundo AND Perceptron:\", weights_and_2)\n",
        "print(\"Pesos do XOR Perceptron:\", weights_xor)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "\n",
            "3. Porque o resultado deu errado na questão anterior?\n",
            "O número de iterações não foi o suficiente para o Perceptron encontrar os pesos ótimos.\n",
            "Pesos do primeiro AND Perceptron: [0.11 0.11]\n",
            "Pesos do segundo AND Perceptron: [0.01 0.01]\n",
            "Pesos do XOR Perceptron: [0.11 0.11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KZ19-RLkW4w"
      },
      "source": [
        "4. Atualize a função de ativação do perceptron para a função sigmóide. \n",
        "\n",
        "OBS: Essa atualização fará o Percetron se transformar na Rede Neural Adaline, que utiliza uma função de ativação contínua ao invés de uma função limiar binária."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M4NMoDikbA5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron_to_Adaline(object):\n",
        "\n",
        "    def __init__(self, no_of_inputs, threshold=0.5, nIterations=100, learning_rate=0.01):\n",
        "        self.nIterations = nIterations\n",
        "        self.threshold = threshold\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.zeros(no_of_inputs)\n",
        "           \n",
        "    def predict(self, inputs):\n",
        "        #.dot = produto de dois arrays (somatório entre entrada e peso)\n",
        "        summation = np.dot(inputs, self.weights)\n",
        "        #print(\"summation:\", summation)\n",
        "        summation = 1/(1 + np.exp(-summation))\n",
        "        if summation >= self.threshold:\n",
        "          activation = 1\n",
        "        else:\n",
        "          activation = 0            \n",
        "        return activation\n",
        "\n",
        "    def train(self, training_inputs, labels):\n",
        "        for _ in range(self.nIterations):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                #delta = w_i + n*(t-o)*x\n",
        "                delta = self.learning_rate * (label - prediction) * inputs\n",
        "                #w_(i+1) = w_i + delta \n",
        "                self.weights += delta\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0fiUIJIkYcQ"
      },
      "source": [
        "5. Agora, altere o código para que execute a base de dados Diabetes como Entrada. Avalie os hiperparâmetros abaixo nas redes Perceptron e Adaline, e diga a taxa de acerto no conjunto de testes pra cada configuração.\n",
        "a) Taxa de Aprendizado = 0.01 e Limiar= 0.2\n",
        "b) Taxa de Aprendizado = 0.1 e Limiar= 0.2\n",
        "c) Taxa de Aprendizado = 0.01 e Limiar= 0.5\n",
        "d) Taxa de Aprendizado = 0.1 e Limiar= 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq9HZFUYkc5D",
        "outputId": "65ef9942-b8e0-4c2d-fe14-6dcde46de265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_esp/Perceptron/diabetes.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a última coluna (rótulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#chama função que carrega base de dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "#Treina Perceptron\n",
        "perceptron = Perceptron(8)\n",
        "perceptron.train(training_inputs.values, training_labels.values)\n",
        "\n",
        "#Avalia primeiro elemento do conjunto de testes\n",
        "p = perceptron.predict(test_inputs.iloc[0].values) \n",
        "print('predicted: ', p)\n",
        "print('label: ', test_labels.iloc[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted:  1\n",
            "label:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvgUpr_ebei8"
      },
      "source": [
        "def testing(model, my_inputs, my_labels):\n",
        "  errors = list()\n",
        "  for input, label in zip(my_inputs, my_labels):\n",
        "    output = model.predict(input)\n",
        "    if(output != label):\n",
        "      errors.append((output, label))\n",
        "  error_rate = len(errors) / len(my_labels)\n",
        "  hit_rate = 1 - error_rate\n",
        "  print('Total de entradas: {}\\nTotal de Erros: {}\\nTaxa de erro: {}\\nTaxa de Acerto: {}'.format(len(my_labels), len(errors), error_rate, hit_rate))\n",
        "\n",
        "  #return errors, my_labels"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5bcSS6nd9A8",
        "outputId": "15b9f915-12f9-41f6-a17e-6e6221e35419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "taxas_aprendizado = [0.01, 0.1, 0.01, 0.1]\n",
        "limiares = [0.2, 0.2, 0.5, 0.5]\n",
        "\n",
        "for taxa_aprendizado, limiar in zip(taxas_aprendizado, limiares):\n",
        "  print('#################')\n",
        "  print('Treinando Perceptron com Taxa de Aprendizado: {} e Limiar: {}'.format(taxa_aprendizado, limiar))\n",
        "  perceptron = Perceptron(8, learning_rate=taxa_aprendizado, threshold=limiar)\n",
        "  perceptron.train(training_inputs.values, training_labels.values)\n",
        "  testing(perceptron, test_inputs.values, test_labels.values)\n",
        "  print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################\n",
            "Treinando Perceptron com Taxa de Aprendizado: 0.01 e Limiar: 0.2\n",
            "Total de entradas: 154\n",
            "Total de Erros: 39\n",
            "Taxa de erro: 0.2532467532467532\n",
            "Taxa de Acerto: 0.7467532467532467\n",
            "\n",
            "#################\n",
            "Treinando Perceptron com Taxa de Aprendizado: 0.1 e Limiar: 0.2\n",
            "Total de entradas: 154\n",
            "Total de Erros: 42\n",
            "Taxa de erro: 0.2727272727272727\n",
            "Taxa de Acerto: 0.7272727272727273\n",
            "\n",
            "#################\n",
            "Treinando Perceptron com Taxa de Aprendizado: 0.01 e Limiar: 0.5\n",
            "Total de entradas: 154\n",
            "Total de Erros: 36\n",
            "Taxa de erro: 0.23376623376623376\n",
            "Taxa de Acerto: 0.7662337662337663\n",
            "\n",
            "#################\n",
            "Treinando Perceptron com Taxa de Aprendizado: 0.1 e Limiar: 0.5\n",
            "Total de entradas: 154\n",
            "Total de Erros: 39\n",
            "Taxa de erro: 0.2532467532467532\n",
            "Taxa de Acerto: 0.7467532467532467\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1O0mouQiszS",
        "outputId": "344abd13-a8f6-4a31-eec3-472f046c608c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "taxas_aprendizado = [0.01, 0.1, 0.01, 0.1]\n",
        "limiares = [0.2, 0.2, 0.5, 0.5]\n",
        "\n",
        "for taxa_aprendizado, limiar in zip(taxas_aprendizado, limiares):\n",
        "  print('#################')\n",
        "  print('Treinando Adaline com Taxa de Aprendizado: {} e Limiar: {}'.format(taxa_aprendizado, limiar))\n",
        "  adaline = Perceptron_to_Adaline(8, learning_rate=taxa_aprendizado, threshold=limiar)\n",
        "  adaline.train(training_inputs.values, training_labels.values)\n",
        "  testing(adaline, test_inputs.values, test_labels.values)\n",
        "  print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################\n",
            "Treinando Adaline com Taxa de Aprendizado: 0.01 e Limiar: 0.2\n",
            "Total de entradas: 154\n",
            "Total de Erros: 87\n",
            "Taxa de erro: 0.564935064935065\n",
            "Taxa de Acerto: 0.43506493506493504\n",
            "\n",
            "#################\n",
            "Treinando Adaline com Taxa de Aprendizado: 0.1 e Limiar: 0.2\n",
            "Total de entradas: 154\n",
            "Total de Erros: 90\n",
            "Taxa de erro: 0.5844155844155844\n",
            "Taxa de Acerto: 0.4155844155844156\n",
            "\n",
            "#################\n",
            "Treinando Adaline com Taxa de Aprendizado: 0.01 e Limiar: 0.5\n",
            "Total de entradas: 154\n",
            "Total de Erros: 44\n",
            "Taxa de erro: 0.2857142857142857\n",
            "Taxa de Acerto: 0.7142857142857143\n",
            "\n",
            "#################\n",
            "Treinando Adaline com Taxa de Aprendizado: 0.1 e Limiar: 0.5\n",
            "Total de entradas: 154\n",
            "Total de Erros: 44\n",
            "Taxa de erro: 0.2857142857142857\n",
            "Taxa de Acerto: 0.7142857142857143\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}