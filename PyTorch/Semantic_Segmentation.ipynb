{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_esp/blob/main/PyTorch/Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDhrB-X28MFB"
      },
      "source": [
        "#Segmentação Semântica\n",
        "\n",
        "Refere-se ao processo de classificação de cada pixel em uma imagem a um rótulo de classe. Esses rótulos são os objetos que se destacam em uma imagem, como pessoas, uma célula, uma árvore, um carro, só pra citar alguns. Esse tipo de segmentação pode ser muito útil em aplicações ​​para contar o número de objetos, como a contagem do tráfego de pedestres em um shopping, número de células numa imagem, etc. Pra mais informações, veja este artigo no [medium](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1NywF5EJbih"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, utils\n",
        "from torch import nn\n",
        "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensor\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "import tarfile\n",
        "import warnings\n",
        "import random\n",
        "import sys\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRVPWhsv01IG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WYUNojkQmX1"
      },
      "source": [
        "## Carregando a Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwtiP-8vJmA4"
      },
      "source": [
        "#path = os.path.join(os.getcwd(), 'gdrive', 'My Drive', 'Dataset')   # Change according to your path \n",
        "path = os.path.join(os.getcwd())   # Change according to your path\n",
        "os.chdir(path)\n",
        "print('path: ' + path)\n",
        "zip_path = path + '/gdrive/My Drive/Dataset'\n",
        "\n",
        "#path = os.path.join(os.getcwd(), 'gdrive', 'My Drive', 'Dataset')   # Change according to your path \n",
        "path = os.path.join(os.getcwd())   # Change according to your path\n",
        "os.chdir(path)\n",
        "\n",
        "if(not os.path.isdir(path + '/data/stage1_train/')):\n",
        "  with tarfile.open(zip_path + '/data-science-bowl-2018.tar', 'r:tar') as tar:\n",
        "      tar.extractall('data')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAgSxvJkNdoG"
      },
      "source": [
        "def get_transforms(mean, std):\n",
        "            list_transforms = []\n",
        "            \n",
        "            list_transforms.extend(\n",
        "                    [\n",
        "                HorizontalFlip(p=0.5), # only horizontal flip as of now\n",
        "                    ])\n",
        "            list_transforms.extend(\n",
        "                    [\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            ToTensor(),\n",
        "                    ])\n",
        "            list_trfms = Compose(list_transforms)\n",
        "            return list_trfms\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Nuclie_data(Dataset):\n",
        "        samples = []\n",
        "        classes = []\n",
        "        def __init__(self,path):\n",
        "            self.path = path\n",
        "            self.transforms = get_transforms(0.5, 0.5)\n",
        "\n",
        "            # Set some parameters\n",
        "            IMG_WIDTH = 128\n",
        "            IMG_HEIGHT = 128\n",
        "            IMG_CHANNELS = 3\n",
        "            width_out = 128\n",
        "            height_out = 128\n",
        "            TRAIN_PATH = '/content/data/stage1_train/'\n",
        "            TEST_PATH = '/content/data/stage1_test/'\n",
        "\n",
        "            self.folders = os.listdir(TRAIN_PATH)\n",
        "\n",
        "            warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "            seed = 42\n",
        "            random.seed = seed\n",
        "            np.random.seed = seed\n",
        " \n",
        "            # Get train and test IDs\n",
        "            train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "            test_ids = next(os.walk(TEST_PATH))[1]\n",
        "\n",
        "            # Get and resize train images and masks\n",
        "            x_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "            y_train = np.zeros((len(train_ids), height_out, width_out, 1), dtype=np.bool)\n",
        "            print('Getting train images and masks ... ')\n",
        "            sys.stdout.flush()\n",
        "            for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "                path = TRAIN_PATH + id_\n",
        "                img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "                img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "                x_train[n] = img\n",
        "                mask = np.zeros((height_out, width_out, 1), dtype=np.bool)\n",
        "                for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "                    mask_ = imread(path + '/masks/' + mask_file)\n",
        "                    mask_ = np.expand_dims(resize(mask_, (height_out, width_out), mode='constant', \n",
        "                                                  preserve_range=True), axis=-1)\n",
        "                    mask = np.maximum(mask, mask_)\n",
        "                y_train[n] = mask\n",
        "\n",
        "\n",
        "\n",
        "            # Get and resize test images\n",
        "            x_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "            sizes_test = []\n",
        "            print('Getting and resizing test images ... ')\n",
        "            sys.stdout.flush()\n",
        "            for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "                path = TEST_PATH + id_\n",
        "                img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "                sizes_test.append([img.shape[0], img.shape[1]])\n",
        "                img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "                x_test[n] = img\n",
        "\n",
        "            #herança da classe Dataset\n",
        "            self.data = x_train\n",
        "            self.labels = y_train\n",
        "\n",
        "            print('Done!')\n",
        "\n",
        "        \n",
        "        def __len__(self):\n",
        "            return len(self.folders)\n",
        "              \n",
        "        \n",
        "        def __getitem__(self,idx):\n",
        "            item = self.data[idx].transpose(2, 0, 1)\n",
        "            label = self.labels[idx].transpose(2, 0, 1)\n",
        "\n",
        "            #if self.transforms is not None:\n",
        "            #   item_as_tensor = tf.convert_to_tensor(item)\n",
        "\n",
        "            if label is not None:\n",
        "                return item,label\n",
        "            else:\n",
        "                return item\n",
        "                \n",
        "'''\n",
        "            image_folder = os.path.join(self.path,self.folders[idx],'images/')\n",
        "            mask_folder = os.path.join(self.path,self.folders[idx],'masks/')\n",
        "            image_path = os.path.join(image_folder,os.listdir(image_folder)[0])\n",
        "            \n",
        "            img = io.imread(image_path)[:,:,:3].astype('float32')\n",
        "            img = transform.resize(img,(128,128))\n",
        "            \n",
        "            mask = self.get_mask(mask_folder, 128, 128 ).astype('float32')\n",
        "\n",
        "            augmented = self.transforms(image=img, mask=mask)\n",
        "            img = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "            mask = mask[0].permute(2, 0, 1)\n",
        "\n",
        "            return (img,mask) \n",
        "\n",
        "\n",
        "            def get_mask(self,mask_folder,IMG_HEIGHT, IMG_WIDTH):\n",
        "                mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "                for mask_ in os.listdir(mask_folder):\n",
        "                        mask_ = io.imread(os.path.join(mask_folder,mask_))\n",
        "                        mask_ = transform.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
        "                        mask_ = np.expand_dims(mask_,axis=-1)\n",
        "                        mask = np.maximum(mask, mask_)\n",
        "                  \n",
        "                return mask\n",
        "'''\n",
        "\n",
        "#loading the data\n",
        "base_dir = path + '/data/' \n",
        "data = Nuclie_data(base_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29v8ApXFJ_NW"
      },
      "source": [
        "# print out some sample data\n",
        "print(data.__len__())\n",
        "data.__getitem__(0)\n",
        "\n",
        "for img,msk in data:\n",
        "  #img = img.reshape(3, 128, 128)\n",
        "  #img = img.transpose(2, 0, 1)\n",
        "  #msk = msk.transpose(2, 0, 1)\n",
        "  print(img.shape)\n",
        "  print(msk.shape)\n",
        "  break\n",
        "  \n",
        "# some utility functions\n",
        "def mask_convert(mask):\n",
        "    mask = mask.clone().cpu().detach().numpy()\n",
        "    mask = mask.transpose((1,2,0))\n",
        "    std = np.array((0.5))\n",
        "    mean = np.array((0.5))\n",
        "    mask  = std * mask + mean\n",
        "    mask = mask.clip(0,1)\n",
        "    mask = np.squeeze(mask)\n",
        "    return mask\n",
        "\n",
        "# converting tensor to image\n",
        "def image_convert(image):\n",
        "    image = image.clone().cpu().numpy()\n",
        "    image = image.transpose((1,2,0))\n",
        "    std = np.array((0.5,0.5,0.5))\n",
        "    mean = np.array((0.5,0.5,0.5))\n",
        "    image  = std * image + mean\n",
        "    image = image.clip(0,1)\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "def plot_img(no_):\n",
        "    iter_ = iter(train_loader)\n",
        "    images,masks = next(iter_)\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    for idx in range(0,no_):\n",
        "         image = image_convert(images[idx])\n",
        "         plt.subplot(2,no_,idx+1)\n",
        "         plt.title('image')\n",
        "         plt.imshow(image)\n",
        "    for idx in range(0,no_):\n",
        "         mask = mask_convert(masks[idx])\n",
        "         plt.subplot(2,no_,idx+no_+1)\n",
        "         plt.title('mask')\n",
        "         plt.imshow(mask,cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWng5470OG_F"
      },
      "source": [
        "# splitting to trainset and validation set and loading the data with batch size of 10\n",
        "print(data)\n",
        "trainset, valset = random_split(data, [580, 90])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=valset, batch_size=10)\n",
        "\n",
        "# we will try visualizing images and corresponding masks\n",
        "plot_img(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIyXnc5JAFlz"
      },
      "source": [
        "##2. Unet\n",
        "Unet e uma Rede neural de segmentação semântica amplamente utilizada e alterada na literatura pra diversos problemas de segmentação\n",
        "\n",
        "A arquitetura do Unet pode ser dividida em duas partes esquerda (caminho de contratação) e direita (caminho de expansão).\n",
        "\n",
        "![](https://github.com/valmirf/redes_neurais_esp/blob/main/PyTorch/FIG/Unet.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMtlEQch8G9i"
      },
      "source": [
        "#double 3x3 convolution \n",
        "def dual_conv(in_channel, out_channel):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, out_channel, kernel_size=3),\n",
        "        nn.ReLU(inplace= True),\n",
        "        nn.Conv2d(out_channel, out_channel, kernel_size=3),\n",
        "        nn.ReLU(inplace= True),\n",
        "    )\n",
        "    return conv\n",
        "\n",
        "# crop the image(tensor) to equal size \n",
        "# as shown in architecture image , half left side image is concated with right side image\n",
        "def crop_tensor(target_tensor, tensor):\n",
        "    target_size = target_tensor.size()[2]\n",
        "    tensor_size = tensor.size()[2]\n",
        "    delta = tensor_size - target_size\n",
        "    delta = delta // 2\n",
        "\n",
        "    return tensor[:, :, delta:tensor_size- delta, delta:tensor_size-delta]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4F0DwwLBVV7"
      },
      "source": [
        "A parte esquerda da rede Unet é apenas uma rede de convolução simples. Na parte esquerda duas camadas de convolução 3x3 seguidas por uma função de ativação Relu são empilhadas juntas (sequencialmente) e uma camada maxpool 2x2 é aplicada depois disso (**seta vermelha** na imagem). A primeira barra vertical no lado esquerdo da imagem não é uma camada, mas representa a entrada (bloco da imagem de entrada).\n",
        "\n",
        "A parte direita é onde a mágica acontece. A parte direita também usa duas camadas de convolução 3x3 empilhadas juntas (sequencialmente) como o lado esquerdo, mas nenhuma função de ativação Relu é usada e não há nenhuma camada maxpool usada. No lugar dessas camadas, é utilizada uma camada de convolução 2x2 Transposta (**seta verde** na imagem). Durante o caminho de expansão, a imagem é copiada (cópia) do lado esquerdo e combinada com a imagem da direita (**seta cinza** na imagem). \n",
        "\n",
        "As camadas de convolução 3x3 sequenciais também são usadas no lado direito, de modo que a entrada para delas será a combinação da imagem da direita e sua camada anterior (metade da caixa branca e azul no lado direito da imagem é a combinação)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVElLUnz8pC6"
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dblock1 = double_conv(3, 64)\n",
        "        self.dblock2 = double_conv(64, 128)\n",
        "        self.dblock3 = double_conv(128,256)\n",
        "        self.dblock4 = double_conv(256,512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) \n",
        "\n",
        "        self.dblock5 = double_conv(256 + 512, 256)\n",
        "        self.dblock6 = double_conv(128 + 256, 128)\n",
        "        self.dblock7 = double_conv(128 + 64, 64)\n",
        "\n",
        "        self.last_layer = nn.Conv2d(64,1,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        conv1 = self.dblock1(x)\n",
        "        x = self.pool(conv1)\n",
        "\n",
        "        conv2 = self.dblock2(x)\n",
        "        x = self.pool(conv2)\n",
        "\n",
        "        conv3 = self.dblock3(x)\n",
        "        x = self.pool(conv3)\n",
        "\n",
        "        conv4 = self.dblock4(x)\n",
        "        \n",
        "        x = self.upsample(conv4)\n",
        "\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dblock5(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "        \n",
        "        x = self.dblock6(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "        \n",
        "        x = self.dblock7(x)\n",
        "\n",
        "        out = self.last_layer(x)\n",
        "        # out = self.sigmoid(x)\n",
        "        return out\n",
        "\n",
        "# initialize the NN\n",
        "model = Unet().to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJUxCXreHLTd"
      },
      "source": [
        "Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zML6NxZ1HMfe"
      },
      "source": [
        "import time\n",
        "def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n",
        "    start = time.time()\n",
        "    model.cuda()\n",
        "\n",
        "    train_loss, valid_loss = [], []\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)  # Set trainind mode = true\n",
        "                dataloader = train_dl\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "                dataloader = valid_dl\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "\n",
        "            step = 0\n",
        "\n",
        "            # iterate over data\n",
        "            for x, y in dataloader:\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "                step += 1\n",
        "\n",
        "                # forward pass\n",
        "                if phase == 'train':\n",
        "                    # zero the gradients\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(x)\n",
        "                    loss = loss_fn(outputs, y)\n",
        "\n",
        "                    # the backward pass frees the graph memory, so there is no \n",
        "                    # need for torch.no_grad in this training pass\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    # scheduler.step()\n",
        "\n",
        "                else:\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(x)\n",
        "                        loss = loss_fn(outputs, y.long())\n",
        "\n",
        "                # stats - whatever is the phase\n",
        "                acc = acc_fn(outputs, y)\n",
        "\n",
        "                running_acc  += acc*dataloader.batch_size\n",
        "                running_loss += loss*dataloader.batch_size \n",
        "\n",
        "                if step % 10 == 0:\n",
        "                    # clear_output(wait=True)\n",
        "                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n",
        "                    # print(torch.cuda.memory_summary())\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_acc / len(dataloader.dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
        "    \n",
        "    return train_loss, valid_loss    \n",
        "\n",
        "def acc_metric(predb, yb):\n",
        "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwXNgHm4IY8O"
      },
      "source": [
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)       \n",
        "        bce_weight = 0.5\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        loss_final = BCE * bce_weight + dice_loss * (1 - bce_weight)\n",
        "        return loss_final\n",
        "    \n",
        "## IOU computation\n",
        "def iou_(y_pred,y):\n",
        "    inputs = y_pred.reshape(-1)\n",
        "    targets = y.reshape(-1)\n",
        "    intersection = (inputs * targets).sum()\n",
        "    total = (inputs + targets).sum()\n",
        "    union = total - intersection \n",
        "    smooth = 1    \n",
        "    iou = (intersection + smooth)/(union + smooth)\n",
        "    return iou\n",
        "\n",
        "\n",
        "\n",
        "def iou_batch(y_pred,y):\n",
        "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
        "    ious = []\n",
        "    y_pred = F.sigmoid(y_pred)\n",
        "    y_pred = y_pred.clone().cpu().detach().numpy()\n",
        "    y = y.clone().cpu().detach().numpy() \n",
        "    \n",
        "    for pred, label in zip(y_pred, y):\n",
        "        ious.append(iou_(pred, label))\n",
        "    iou = np.nanmean(ious)\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4bYUcDc45QG"
      },
      "source": [
        "#ref https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee\n",
        "\n",
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, checkpoint_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(checkpoint_path, best_model_path)\n",
        "        \n",
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwmA8hWr4-qm"
      },
      "source": [
        "checkpoint_path = '/chkpoint_'\n",
        "best_model_path = '/bestmodel.pt'\n",
        "epochs = 25\n",
        "criterion = DiceBCELoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "valid_loss_min = 3.95275\n",
        "\n",
        "\n",
        "train_loss,val_loss = [],[]\n",
        "train_iou,val_iou = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "    start_time = time.time()\n",
        "     \n",
        "\n",
        "    \n",
        "    running_train_loss = []\n",
        "    running_train_score = []\n",
        "    for image,mask in train_loader: \n",
        "            image = image.to(device,dtype=torch.float)\n",
        "            mask = mask.to(device,dtype=torch.float)\n",
        "            pred_mask = model.forward(image) # forward propogation\n",
        "            loss = criterion(pred_mask,mask)\n",
        "            score = iou_batch(pred_mask,mask)\n",
        "            optimizer.zero_grad() # setting gradient to zero\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss.append(loss.item())\n",
        "            running_train_score.append(score)\n",
        "                              \n",
        "\n",
        "    else:           \n",
        "        running_val_loss = []\n",
        "        running_val_score = []\n",
        "        with torch.no_grad():\n",
        "            for image,mask in val_loader:\n",
        "                    image = image.to(device,dtype=torch.float)\n",
        "                    mask = mask.to(device,dtype=torch.float)                            \n",
        "                    pred_mask = model.forward(image)\n",
        "                    loss = criterion(pred_mask,mask)\n",
        "                    score = iou_batch(pred_mask,mask)\n",
        "                    running_val_loss.append(loss.item())\n",
        "                    running_val_score.append(score)\n",
        "\n",
        "                                    \n",
        "    \n",
        "    epoch_train_loss,epoch_train_score = np.mean(running_train_loss) ,np.mean(running_train_score)\n",
        "    print('Train loss : {} iou : {}'.format(epoch_train_loss,epoch_train_score))                       \n",
        "    train_loss.append(epoch_train_loss)\n",
        "    train_iou.append(epoch_train_score)\n",
        "    \n",
        "    epoch_val_loss,epoch_val_score = np.mean(running_val_loss),np.mean(running_val_score)\n",
        "    print('Validation loss : {} iou : {}'.format(epoch_val_loss,epoch_val_score))                                \n",
        "    val_loss.append(epoch_val_loss)\n",
        "    val_iou.append(epoch_val_score)\n",
        "    \n",
        "    # create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'valid_loss_min': epoch_val_loss,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }\n",
        "    \n",
        "    # save checkpoint\n",
        "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "    ## TODO: save the model if validation loss has decreased\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "            # save checkpoint as best model\n",
        "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "            valid_loss_min = epoch_val_loss\n",
        "    \n",
        "    time_elapsed = time.time() - start_time\n",
        "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "609eBwSe5DSe"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss,label='train_loss')\n",
        "plt.plot(val_loss,label='val_loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Plot')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_iou,label='train_iou')\n",
        "plt.plot(val_iou,label='val_iou')\n",
        "plt.legend()\n",
        "plt.title('IOU Plot')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY90shhK5IWN"
      },
      "source": [
        "#loading the saved model\n",
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(checkpoint_path, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNI3H-t-5K-A"
      },
      "source": [
        "iter_ = iter(val_loader)\n",
        "image,mask = next(iter_)\n",
        "image = image.to(device,dtype=torch.float)\n",
        "mask = mask.to(device,dtype=torch.float)\n",
        "y_pred = model.forward(image)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "for i in range(0,5):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    plt.title('Actual image') \n",
        "    plt.imshow(image_convert(image[i]))\n",
        "for i in range(0,5):\n",
        "    plt.subplot(3,5,i+5+1)\n",
        "    plt.title('Actual mask')\n",
        "    plt.imshow(mask_convert(mask[i]),cmap='gray')\n",
        "for i in range(0,5):\n",
        "    plt.subplot(3,5,i+10+1)\n",
        "    plt.title('Predicted mask')\n",
        "    plt.imshow(mask_convert(y_pred[i]),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}